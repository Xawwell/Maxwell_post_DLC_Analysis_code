{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af230fbe-6ff6-4af7-a615-1e18075af7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages and set global variables\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Global variables\n",
    "PARENT_PATH = r\"G:\\Files_from_npx_bonzai_pc\\raw_data\"\n",
    "N_CHANNELS = 5\n",
    "channel_labels = ['Camera_trigger', 'Audio_output', 'Photodiode', 'Probe_sync', 'Microphone']\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2127affd-7740-4953-afe9-591a9e00372a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Getting all the analog signals\n",
    "\n",
    "def get_all_data(mouse_id):\n",
    "    \"\"\"\n",
    "    Retrieve data for a given mouse identified by its ID.\n",
    "\n",
    "    The function searches for a directory matching the mouse_id and reads\n",
    "    \"analogy.bin,\" \"block_timers.csv,\" and \"cam_metadata.csv\" files in that directory.\n",
    "\n",
    "    Parameters:\n",
    "    - mouse_id (int or str): Unique identifier for the mouse.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing data from \"analogy.bin,\" \"block_timers.csv,\" and \"cam_metadata.csv\"\n",
    "             as separate variables, and the path to the mouse directory.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If no directory is found for the given mouse ID.\n",
    "    \"\"\"\n",
    "    directory = pathlib.Path(PARENT_PATH)\n",
    "    mouse_directory = [folder for folder in directory.iterdir() if f\"mouseid-{mouse_id}\" in folder.name]\n",
    "\n",
    "    if not mouse_directory:\n",
    "        raise ValueError(f\"No directory found for mouse ID: {mouse_id}\")\n",
    "\n",
    "    # Read analogy.bin\n",
    "    analogy_bin_path = list(mouse_directory[0].rglob('*.bin'))[0]\n",
    "    analogy_bin_data = np.fromfile(str(analogy_bin_path))\n",
    "    reshaped_analogy_data = analogy_bin_data.reshape(int(analogy_bin_data.shape[0] / N_CHANNELS), N_CHANNELS)\n",
    "    #Assign channels to the analogy files\n",
    "    binary_channels = assign_channels_to_dict(reshaped_analogy_data)\n",
    "\n",
    "    # Read block_timers.csv\n",
    "    block_timers_path = list(mouse_directory[0].rglob('block_timers.csv'))[0]\n",
    "    block_timers_data = pd.read_csv(block_timers_path)\n",
    "\n",
    "    # Read cam_metadata.csv\n",
    "    cam_metadata_path = list(mouse_directory[0].rglob('cam_metadata.csv'))[0]\n",
    "    cam_metadata_data = pd.read_csv(cam_metadata_path, usecols=[0, 1, 2, 4], \n",
    "                                    header=None, \n",
    "                                    names=['frame number', 'zero', 'timestamp_in_tick', 'stage_id'],\n",
    "                                    skiprows=1)\n",
    "    # This is because the units are by ticks, where 1 tick = 1/125000 miliseconds, or 8 nanoseconds\n",
    "\n",
    "    return binary_channels, block_timers_data, cam_metadata_data, mouse_directory[0]\n",
    "\n",
    "\n",
    "def assign_channels_to_dict(bonsai_binary_data):\n",
    "    \"\"\"\n",
    "    Assign binary data from multiple channels to a dictionary with channel labels.\n",
    "\n",
    "    Parameters:\n",
    "    - bonsai_binary_data (numpy.ndarray): 2D array with binary data from multiple channels.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary mapping channel labels to their respective binary data.\n",
    "    \"\"\"\n",
    "    binary_channels = {}\n",
    "    for channel, channel_label in zip(bonsai_binary_data.T, channel_labels):\n",
    "        binary_channels[channel_label] = channel\n",
    "    return binary_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1973f1a-9563-4599-a254-562c0a76418a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read the binary data from the specified file.\n",
    "mouse_id = \"1119623\"\n",
    "binary_channels, block_timers_data, cam_metadata, mouse_directory  = get_all_data(mouse_id)\n",
    "audio_data = binary_channels['Audio_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1bfefc-0f1d-4355-a1ac-6d48d4cdc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustered_audio_stimulus_timing(data: np.ndarray, sampling_rate: int, threshold: float, min_interval: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Identify the onsets and durations of audio stimuli from a signal, clustering close events as one.\n",
    "\n",
    "    :param data: Audio signal data as a numpy array.\n",
    "    :param sampling_rate: The sampling rate of the audio data (in Hz).\n",
    "    :param threshold: Threshold value to determine stimulus 'on' state.\n",
    "    :param min_interval: Minimum interval in seconds to separate distinct audio stimuli.\n",
    "    :return: A tuple of two numpy arrays: clustered onset times and durations, both in seconds.\n",
    "    \"\"\"\n",
    "    # Detecting stimulus presence\n",
    "    stimulus_present = data > threshold\n",
    "    changes = np.diff(stimulus_present.astype(int))\n",
    "    onset_indices = np.where(changes == 1)[0] + 1\n",
    "    offset_indices = np.where(changes == -1)[0] + 1\n",
    "\n",
    "    # Handling signal start or end with ongoing stimulus\n",
    "    if stimulus_present[0]:\n",
    "        onset_indices = np.insert(onset_indices, 0, 0)\n",
    "    if stimulus_present[-1]:\n",
    "        offset_indices = np.append(offset_indices, len(data) - 1)\n",
    "\n",
    "    # Convert indices to time\n",
    "    onset_times = onset_indices / sampling_rate\n",
    "    offset_times = offset_indices / sampling_rate\n",
    "\n",
    "    # Clustering closely spaced onsets\n",
    "    clustered_onsets = []\n",
    "    clustered_offsets = []\n",
    "\n",
    "    for i in range(len(onset_times)):\n",
    "        if not clustered_onsets:\n",
    "            # Add the first onset and corresponding offset\n",
    "            clustered_onsets.append(onset_times[i])\n",
    "            clustered_offsets.append(offset_times[i])\n",
    "        else:\n",
    "            if onset_times[i] - clustered_offsets[-1] < min_interval:\n",
    "                # Extend the current event\n",
    "                clustered_offsets[-1] = offset_times[i]\n",
    "            else:\n",
    "                # Start a new event\n",
    "                clustered_onsets.append(onset_times[i])\n",
    "                clustered_offsets.append(offset_times[i])\n",
    "\n",
    "    # Calculating durations\n",
    "    durations = np.array(clustered_offsets) - np.array(clustered_onsets)\n",
    "\n",
    "    return np.array(clustered_onsets), durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a475eb5-8e8c-4713-a6c0-7a8535127fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 795.95023333, 3088.2766    , 3668.90103333, 7563.58256667]),\n",
       " array([ 2.10136667, 10.00063333, 10.00066667,  0.72116667]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_onset_times, clustered_durations = get_clustered_audio_stimulus_timing(audio_data, 30000,0.1, 0.5)  # 0.04 seconds as an example min_interval\n",
    "\n",
    "# Display the first few clustered onsets and durations\n",
    "clustered_onset_times[:10], clustered_durations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764da334-f352-4851-b5ab-d881a6e6b107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11572\\146072086.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### save these arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clustered_onset_times.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclustered_onset_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clustered_durations.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclustered_durations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "### save these arrays\n",
    "np.save('clustered_onset_times.npy', clustered_onset_times)\n",
    "np.save('clustered_durations.npy', clustered_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5510f7-ae6b-4199-9914-3d2bb65e3034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
